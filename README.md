# WMT19SrcDA

Instructions and issue tracker for WMT19 reference-based DA campaigns

## TL;DR

- Find the login page here: https://wmt19.waypost.net/
- WMT19 will feature reference-based direct assessment (DA), carried out by research teams
- This evaluation will be based on segment-level annotation
- Language pairs we are currently running are: DE-CS, DE-FR, CS-DE, ZH-EN
- To participate, **you need to be proficient in one of the target languages only (CS, DE, FR or EN)**
- Please use the [Github issue tracker](https://github.com/bricksdont/WMT19RefDA/issues) to report any problems, confusing or missing instructions

## Timeline

- 5/10--5/15: research teams request accounts
- 5/15: instructions online on Github
- 5/15: notification sent out to teams, annotation starts
- 5/27: annotation ends

## Updates

- 5/22: Clarified annotation workload for ZH-EN

## Campaign overview

### How will the annotation work?

Annotations will be collected in Turkle, implementing segment-level,
reference-based direct assessment. For every language pair, there will be a
pre-generated amount of annotations tasks ("HITs").

Users are trusted to select a task with a target language they are proficient in. For instance, users that speak German should accept tasks from `wmt19-fr-de`.

### How much annotation work is needed?

Based on previous WMT evaluation campaigns, the average annotation time for one task is 30 minutes. One task involves approximately 100 judgements.

Each research team is expected to contribute **eight hours of annotation work
per primary system** submission. You can allocate those work hours either

- in this campaign (the instructions you are looking at right now)
- or in our source-based evaluation campaign on Appraise, run by Christian Federmann: https://github.com/cfedermann/WMT19SrcDA

This translates to **16 completed tasks** in total, on Turkle or Appraise, per primary system.

**Update and clarification 5/22**: We are now aware that some tasks in ZH-EN take longer due to long sentences. If that is the case for you, please stop after 8 hours instead of 16 tasks. Be prepared to explain when we are checking team contributions.

### Who can be an annotator?

The reference-based evaluation campaign is currently run for the following target languages: CS, FR, DE, EN. **To participate in this evaluation, you need to be proficient in one of those languages.**

### How are accounts distributed?

We kindly ask you to sign up in this Google form: https://forms.gle/tcNiaiJpoyqi2hZ79, with your preferred user name. We will create this account on Turkle for you, and reach out to you by email to confirm.

### How can I sign into Turkle?

Please go to https://wmt19.waypost.net/ and use 1) the username you indicated in the Google form and 2) the initial password we sent to you by email.

**Please change your initial password before accepting any tasks**

### How does reference-based DA work?

You are shown two sentences at a time, both in the same language. Your task is to judge whether the second sentence has the same meaning as the first.

### How can I report problems?

Please use the [Github issue tracker](https://github.com/bricksdont/WMT19RefDA/issues)
to report any problems. For urgent problems you can also contact

- Matt via `post [at] cs [dot] jhu [dot] edu`
- Mathias via `mmueller [at] cl [dot] uzh [dot] ch`

Thank you for your participation!
